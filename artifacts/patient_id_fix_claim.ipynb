{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "microsoft": {}
      },
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "claim_main_df = spark.sql(\"SELECT * FROM `fhir`.`claim_main_hash`\")\n",
        "\n",
        "claim_main_df = claim_main_df.withColumn(\"patient_reference\",regexp_replace(\"patient_reference\",\"Patient/\",\"\")).withColumn(\"provider_reference\",regexp_replace(\"provider_reference\",\"Organization/\",\"\"))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "display(claim_main_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {}
      },
      "source": [
        "silver_location = \"abfss://silver@prsynapselab.dfs.core.windows.net/\"\r\n",
        "write_mode=\"overwrite\"\r\n",
        "claim_main_df.coalesce(200).write.format(\"delta\").option(\"path\", silver_location+\"claim_main\").mode(write_mode).saveAsTable(\"fhir.claim_main_hash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "SET spark.databricks.delta.retentionDurationCheck.enabled = false"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "VACUUM `fhir`.`claim_main_hash` RETAIN 1 HOURS "
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}